{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stock Market Deep.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vJxWlDAzjeIa"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chettkulkarni/Reinforcement_Learning/blob/main/Stock_Market_Final_Collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kuUeJECeDNk"
      },
      "source": [
        "#Automatic Stock Trading Using Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCuVeBPBeNNe"
      },
      "source": [
        "In this project we aim to build a deep reinforcement learning scheme that automatically learns a stock trading strategy by maximizing investment return.\n",
        "\n",
        "---\n",
        "\n",
        "Hongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy. In ICAIF ’20: ACM International Conference on AI in Finance, Oct. 15–16, 2020, Manhattan, NY. ACM, New York, NY, USA.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Zv7qGqecwc"
      },
      "source": [
        "#Installing necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "quU-xSSsiqZS",
        "outputId": "6b3463e6-3745-404c-b24d-4cab3f905c5a"
      },
      "source": [
        "# Model Building Requirements\n",
        "!pip install numpy==1.16.4\n",
        "!pip install pandas==1.0.3\n",
        "!pip install stockstats\n",
        "!pip install scikit-learn==0.21.0\n",
        "!pip install gym==0.15.3\n",
        "!pip install stable-baselines[mpi]\n",
        "!pip install tensorflow==1.15.4\n",
        "\n",
        "!pip install joblib==0.15.1\n",
        "\n",
        "# plot\n",
        "!pip install matplotlib==3.2.1\n",
        "\n",
        " # testing requirements\n",
        "!pip install pytest>=5.3.2,<6.0.0\n",
        "\n",
        " # packaging\n",
        "!pip install setuptools>=41.4.0,<42.0.0\n",
        "!pip install wheel>=0.33.6,<0.34.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 341kB/s \n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.16.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==1.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/71/8f53bdbcbc67c912b888b40def255767e475402e9df64050019149b1a943/pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.3) (1.15.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "Successfully installed pandas-1.0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting stockstats\n",
            "  Downloading https://files.pythonhosted.org/packages/32/41/d3828c5bc0a262cb3112a4024108a3b019c183fa3b3078bff34bf25abf91/stockstats-0.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from stockstats) (1.0.3)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/43/27/31803df15173ab341fe7548c14154b54227dfd8f630daa09a1c6e7db52f7/int_date-0.1.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from stockstats) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->stockstats) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->stockstats) (2.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from int-date>=0.1.7->stockstats) (1.15.0)\n",
            "Installing collected packages: int-date, stockstats\n",
            "Successfully installed int-date-0.1.8 stockstats-0.3.2\n",
            "Collecting scikit-learn==0.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/6c/ec121123c671d980c6969dfc69d0f09e1d7f88d80d373f511e61d773b85c/scikit_learn-0.21.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.0) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.0) (1.16.4)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.21.0\n",
            "Collecting gym==0.15.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/88/a7186ffe1f33570ad3b8cd635996e5a3e3e155736e180ae6a2ad5e826a60/gym-0.15.3.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.15.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 34.8MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.3-cp36-none-any.whl size=1644971 sha256=7f5de6c2d58c7672501a5cf6d0bd5e1f99c18d040f2646aebb78c33a48fc5c90\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/71/10/30f9b16332ecfd6318ac290445c696fe809bcbe40a05f9a799\n",
            "Successfully built gym\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement cloudpickle==1.3, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed cloudpickle-1.2.2 gym-0.15.3 pyglet-1.3.2\n",
            "Collecting stable-baselines[mpi]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/48/d428b79bd4360727925f9fe34afeea7a9da381da3dc8748df834a349ad1d/stable_baselines-2.10.1-py3-none-any.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.15.3)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Collecting mpi4py; extra == \"mpi\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/8f/bbd8de5ba566dd77e408d8136e2bab7fdf2b97ce06cab830ba8b50a2f588/mpi4py-3.0.3.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.0.3-cp36-cp36m-linux_x86_64.whl size=2074485 sha256=785250d7d4378f24b2908b6c373c3eaa765e6b9c1a22f96c6c9237d3a1731cfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e0/86/2b713dd512199096012ceca61429e12b960888de59818871d6\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py, stable-baselines\n",
            "Successfully installed mpi4py-3.0.3 stable-baselines-2.10.1\n",
            "Collecting tensorflow==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/64/7a19837dd54d3f53b1ce5ae346ab401dde9678e8f233220317000bfdb3e2/tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 49kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.35.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 29.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.33.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.16.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=69082a497e82bdf1a9f306877c30441bd2e8f5f9957737771e8242c5cdd7069c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement cloudpickle==1.3, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n",
            "Collecting joblib==0.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 6.5MB/s \n",
            "\u001b[?25hInstalling collected packages: joblib\n",
            "  Found existing installation: joblib 0.17.0\n",
            "    Uninstalling joblib-0.17.0:\n",
            "      Successfully uninstalled joblib-0.17.0\n",
            "Successfully installed joblib-0.15.1\n",
            "Collecting matplotlib==3.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/4b/52da6b1523d5139d04e02d9e26ceda6146b48f2a4e5d2abfdf1c7bac8c40/matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (1.16.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.1) (1.15.0)\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed matplotlib-3.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: 6.0.0: No such file or directory\n",
            "/bin/bash: 42.0.0: No such file or directory\n",
            "/bin/bash: 0.34.0: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPA7nawjevgw"
      },
      "source": [
        "# Downloading Dataset \n",
        "\n",
        "# Wharton Research Data Services (WRDS)\n",
        "\n",
        "We track and select the Dow Jones 30 stock and use historical daily data from 01/01/2009 to 05/08/2020 to train the agent and test the performance. The dataset is downloaded from Compustat database accessed through Wharton Research Data Services (WRDS)\n",
        "\n",
        "\n",
        "WRDS is a web-based business data research service from The Wharton School of the University of Pennsylvania. Provides access to financial, accounting, banking, economics, marketing, and public policy databases through a uniform, web-based interface. Strengths include deep archives of historical data, a common web interface for access to all WRDS databases, and a variety of output file formats.\n",
        "\n",
        "Source : https://www.library.hbs.edu/Find/Databases/WRDS-Wharton-Research-Data-Services\n",
        "\n",
        "We have acquired copy of data and stored it in our private google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFc_clXzm1Mc",
        "outputId": "d14fa7b6-5abe-448a-a829-dff91ed5e63d"
      },
      "source": [
        "!gdown --id 1BA2CqyCGOxusz39NUS-wG0b3ZN7SviBL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BA2CqyCGOxusz39NUS-wG0b3ZN7SviBL\n",
            "To: /content/data.zip\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\r100% 1.90M/1.90M [00:00<00:00, 60.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T-m7dTQfjOd"
      },
      "source": [
        "Extracting the data and keeping it ready for consumption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yov4gE2mnLaq"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNH9WJxbj1X5",
        "outputId": "4964fc24-cb76-4d76-80a0-d0d3bdba93ba"
      },
      "source": [
        "!pip install preprocessing\n",
        "!pip install config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting preprocessing\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f9/cadc71dbd774398e486f0608fb6746de36f562edf32fc59ebbe94a589c79/preprocessing-0.1.13-py3-none-any.whl (349kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 4.9MB/s \n",
            "\u001b[?25hCollecting nltk==3.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c2/858e0708b497116ae45cf5c6b1f66984ac60729c61e49df6c1c0b808d1e4/nltk-3.2.4.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 9.5MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme==0.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/50/849cd05961e7bafda2e0846ba80fa03f5a16a55fc5acc1d9f6bc79eb6fd9/sphinx_rtd_theme-0.2.4-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.4->preprocessing) (1.15.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.4-cp36-none-any.whl size=1367707 sha256=3224ce60d27b7df3de0f1628d8ddc61958c99143e13726d51c809691e7abd9a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/f1/5c/f667347d86a3a534ba4c0127eed4389f929916e3ec88bb461a\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk, sphinx-rtd-theme, preprocessing\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.2.4 preprocessing-0.1.13 sphinx-rtd-theme-0.2.4\n",
            "Collecting config\n",
            "  Downloading https://files.pythonhosted.org/packages/67/af/a7c8be986afee4cf277045cfdb06605296ff3f1a1de415d62c18a7a33040/config-0.5.0.post0-py2.py3-none-any.whl\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.5.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDumHnIEf3aZ"
      },
      "source": [
        "# Loading Dataset\n",
        "\n",
        "Preprocessing steps :\n",
        "Using Standard formulas we dervie these metrics and joining with turbulence dataset\n",
        "\n",
        "MACD: Moving Average Convergence Divergence (MACD) is calculated using close price. RSI: Relative Strength Index \n",
        "\n",
        "(RSI) is calculated using close price. \n",
        "\n",
        "CCI: Commodity Channel Index (CCI) is calculated using high, low and close price. \n",
        "\n",
        "ADX: Average Directional Index (ADX) is calculated using high, low and close price.\n",
        "\n",
        "Turbulence Index (TI): Market turbulence is the unexpected rising and falling of the stock market. TI signifies turbulence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0J5q7tSgdHG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    load csv dataset from path\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    #_data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data\n",
        "\n",
        "def data_split(df,start,end):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df.datadate >= start) & (df.datadate < end)]\n",
        "    data=data.sort_values(['datadate','tic'],ignore_index=True)\n",
        "    #data  = data[final_columns]\n",
        "    data.index = data.datadate.factorize()[0]\n",
        "    return data\n",
        "\n",
        "def calcualte_price(df):\n",
        "    \"\"\"\n",
        "    calcualte adjusted close price, open-high-low price and volume\n",
        "    :param data: (df) pandas dataframe\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df.copy()\n",
        "    data = data[['datadate', 'tic', 'prccd', 'ajexdi', 'prcod', 'prchd', 'prcld', 'cshtrd']]\n",
        "    data['ajexdi'] = data['ajexdi'].apply(lambda x: 1 if x == 0 else x)\n",
        "\n",
        "    data['adjcp'] = data['prccd'] / data['ajexdi']\n",
        "    data['open'] = data['prcod'] / data['ajexdi']\n",
        "    data['high'] = data['prchd'] / data['ajexdi']\n",
        "    data['low'] = data['prcld'] / data['ajexdi']\n",
        "    data['volume'] = data['cshtrd']\n",
        "\n",
        "    data = data[['datadate', 'tic', 'adjcp', 'open', 'high', 'low', 'volume']]\n",
        "    data = data.sort_values(['tic', 'datadate'], ignore_index=True)\n",
        "    return data\n",
        "\n",
        "def add_technical_indicator(df):\n",
        "    \"\"\"\n",
        "    calcualte technical indicators\n",
        "    use stockstats package to add technical inidactors\n",
        "    :param data: (df) pandas dataframe\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    stock = Sdf.retype(df.copy())\n",
        "\n",
        "    stock['close'] = stock['adjcp']\n",
        "    unique_ticker = stock.tic.unique()\n",
        "\n",
        "    macd = pd.DataFrame()\n",
        "    rsi = pd.DataFrame()\n",
        "    cci = pd.DataFrame()\n",
        "    dx = pd.DataFrame()\n",
        "\n",
        "    #temp = stock[stock.tic == unique_ticker[0]]['macd']\n",
        "    for i in range(len(unique_ticker)):\n",
        "        ## macd\n",
        "        temp_macd = stock[stock.tic == unique_ticker[i]]['macd']\n",
        "        temp_macd = pd.DataFrame(temp_macd)\n",
        "        macd = macd.append(temp_macd, ignore_index=True)\n",
        "        ## rsi\n",
        "        temp_rsi = stock[stock.tic == unique_ticker[i]]['rsi_30']\n",
        "        temp_rsi = pd.DataFrame(temp_rsi)\n",
        "        rsi = rsi.append(temp_rsi, ignore_index=True)\n",
        "        ## cci\n",
        "        temp_cci = stock[stock.tic == unique_ticker[i]]['cci_30']\n",
        "        temp_cci = pd.DataFrame(temp_cci)\n",
        "        cci = cci.append(temp_cci, ignore_index=True)\n",
        "        ## adx\n",
        "        temp_dx = stock[stock.tic == unique_ticker[i]]['dx_30']\n",
        "        temp_dx = pd.DataFrame(temp_dx)\n",
        "        dx = dx.append(temp_dx, ignore_index=True)\n",
        "\n",
        "\n",
        "    df['macd'] = macd\n",
        "    df['rsi'] = rsi\n",
        "    df['cci'] = cci\n",
        "    df['adx'] = dx\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_data():\n",
        "    \"\"\"data preprocessing pipeline\"\"\"\n",
        "\n",
        "    df = load_dataset(file_name=TRAINING_DATA_FILE)\n",
        "    # get data after 2009\n",
        "    df = df[df.datadate>=20090000]\n",
        "    # calcualte adjusted price\n",
        "    df_preprocess = calcualte_price(df)\n",
        "    # add technical indicators using stockstats\n",
        "    df_final=add_technical_indicator(df_preprocess)\n",
        "    # fill the missing values at the beginning\n",
        "    df_final.fillna(method='bfill',inplace=True)\n",
        "    return df_final\n",
        "\n",
        "def add_turbulence(df):\n",
        "    \"\"\"\n",
        "    add turbulence index from a precalcualted dataframe\n",
        "    :param data: (df) pandas dataframe\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    turbulence_index = calcualte_turbulence(df)\n",
        "    df = df.merge(turbulence_index, on='datadate')\n",
        "    df = df.sort_values(['datadate','tic']).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def calcualte_turbulence(df):\n",
        "    \"\"\"calculate turbulence index based on dow 30\"\"\"\n",
        "    # can add other market assets\n",
        "    \n",
        "    df_price_pivot=df.pivot(index='datadate', columns='tic', values='adjcp')\n",
        "    unique_date = df.datadate.unique()\n",
        "    # start after a year\n",
        "    start = 252\n",
        "    turbulence_index = [0]*start\n",
        "    #turbulence_index = [0]\n",
        "    count=0\n",
        "    for i in range(start,len(unique_date)):\n",
        "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
        "        hist_price = df_price_pivot[[n in unique_date[0:i] for n in df_price_pivot.index ]]\n",
        "        cov_temp = hist_price.cov()\n",
        "        current_temp=(current_price - np.mean(hist_price,axis=0))\n",
        "        temp = current_temp.values.dot(np.linalg.inv(cov_temp)).dot(current_temp.values.T)\n",
        "        if temp>0:\n",
        "            count+=1\n",
        "            if count>2:\n",
        "                turbulence_temp = temp[0][0]\n",
        "            else:\n",
        "                #avoid large outlier because of the calculation just begins\n",
        "                turbulence_temp=0\n",
        "        else:\n",
        "            turbulence_temp=0\n",
        "        turbulence_index.append(turbulence_temp)\n",
        "    \n",
        "    \n",
        "    turbulence_index = pd.DataFrame({'datadate':df_price_pivot.index,\n",
        "                                     'turbulence':turbulence_index})\n",
        "    return turbulence_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVoAepVqhT36"
      },
      "source": [
        "## Mapping data input file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WktkFis0Ozy"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUnu2ZxxgDDg"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "#import finrl\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "\n",
        "TRAINING_DATA_FILE = \"/content/data/data/dow_30_2009_2020.csv\"\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "TRAINED_MODEL_DIR = f\"trained_models/{now}\"\n",
        "os.makedirs(TRAINED_MODEL_DIR)\n",
        "TURBULENCE_DATA = \"/content/data/data/dow30_turbulence_index.csv\"\n",
        "TESTING_DATA_FILE = \"test.csv\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK4MHymfinRd"
      },
      "source": [
        "# Training Environment \n",
        "\n",
        "1)intitialse Env variables:\n",
        "\n",
        "2)define sell stock\n",
        "\n",
        "3)define buy stock\n",
        "\n",
        "4)define step function : perform action , get reward and calculate sharpe ratio and return next state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDAEF_85gXP4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# shares normalization factor\n",
        "# 100 shares per trade\n",
        "HMAX_NORMALIZE = 100\n",
        "# initial amount of money we have in our account\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\n",
        "# total number of stocks in our portfolio\n",
        "STOCK_DIM = 30\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "REWARD_SCALING = 1e-4\n",
        "\n",
        "class StockEnvTrain(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df,day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "\n",
        "        # action_space normalization and shape is STOCK_DIM\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False             \n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.cost = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.rewards_memory = []\n",
        "        self.trades = 0\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.state[index+STOCK_DIM+1] > 0:\n",
        "            #update balance\n",
        "            self.state[0] += \\\n",
        "            self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "             (1- TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
        "            self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "             TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        available_amount = self.state[0] // self.state[index+1]\n",
        "        # print('available_amount:{}'.format(available_amount))\n",
        "\n",
        "        #update balance\n",
        "        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                          (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "        self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
        "\n",
        "        self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                          TRANSACTION_FEE_PERCENT\n",
        "        self.trades+=1\n",
        "        \n",
        "    def step(self, actions):\n",
        "\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('results/account_value_train.png')\n",
        "            plt.close()\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            \n",
        "\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('results/account_value_train.csv')\n",
        "\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            actions = actions * HMAX_NORMALIZE\n",
        "\n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "\n",
        "\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            #load next state\n",
        "\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist() \n",
        "        # iteration += 1 \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gql4flKFjKON"
      },
      "source": [
        "# Validation Environment \n",
        "\n",
        "Here we will use turbulance index to assess risk\n",
        "\n",
        "1)intitialse Env variables:\n",
        "\n",
        "2)define sell stock\n",
        "\n",
        "3)define buy stock\n",
        "\n",
        "4)define step function : perform action , get reward and calculate sharpe ratio and return next state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT5GERHEgZZD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# shares normalization factor\n",
        "# 100 shares per trade\n",
        "HMAX_NORMALIZE = 100\n",
        "# initial amount of money we have in our account\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\n",
        "# total number of stocks in our portfolio\n",
        "STOCK_DIM = 30\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "\n",
        "# turbulence index: 90-150 reasonable threshold\n",
        "#TURBULENCE_THRESHOLD = 140\n",
        "REWARD_SCALING = 1e-4\n",
        "\n",
        "class StockEnvValidation(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        # action_space normalization and shape is STOCK_DIM\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.rewards_memory = []\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "        \n",
        "        self.iteration=iteration\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence<self.turbulence_threshold:\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += \\\n",
        "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\n",
        "                \n",
        "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just clear out all positions \n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\n",
        "                self.state[index+STOCK_DIM+1] =0\n",
        "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence< self.turbulence_threshold:\n",
        "            available_amount = self.state[0] // self.state[index+1]\n",
        "            # print('available_amount:{}'.format(available_amount))\n",
        "            \n",
        "            #update balance\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
        "            \n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just stop buying\n",
        "            pass\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('results/account_value_validation_{}.png'.format(self.iteration))\n",
        "            plt.close()\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('results/account_value_validation_{}.csv'.format(self.iteration))\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- self.asset_memory[0] ))\n",
        "            #print(\"total_cost: \", self.cost)\n",
        "            #print(\"total trades: \", self.trades)\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            #print(\"Sharpe: \",sharpe)\n",
        "            \n",
        "            #df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            #df_rewards.to_csv('results/account_rewards_trade_{}.csv'.format(self.iteration))\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * HMAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            if self.turbulence>=self.turbulence_threshold:\n",
        "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            self.turbulence = self.data['turbulence'].values[0]\n",
        "            #print(self.turbulence)\n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):  \n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        #self.iteration=self.iteration\n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist()  + \\\n",
        "                      self.data.cci.values.tolist()  + \\\n",
        "                      self.data.adx.values.tolist() \n",
        "            \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human',close=False):\n",
        "        return self.state\n",
        "    \n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBG5spoBha6w"
      },
      "source": [
        "# Testing/Trading Environment \n",
        "\n",
        "1)intitialse Env variables:\n",
        "\n",
        "2)define sell stock\n",
        "\n",
        "3)define buy stock\n",
        "\n",
        "4)define step function : perform action , get reward and calculate sharpe ratio and return next state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRlTr3g4gOhW"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# shares normalization factor\n",
        "# 100 shares per trade\n",
        "HMAX_NORMALIZE = 100\n",
        "# initial amount of money we have in our account\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\n",
        "# total number of stocks in our portfolio\n",
        "STOCK_DIM = 30\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "\n",
        "# turbulence index: 90-150 reasonable threshold\n",
        "#TURBULENCE_THRESHOLD = 140\n",
        "REWARD_SCALING = 1e-4\n",
        "\n",
        "class StockEnvTrade(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df,day = 0,turbulence_threshold=140\n",
        "                 ,initial=True, previous_state=[], model_name='', iteration=''):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        # action_space normalization and shape is STOCK_DIM\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initialize state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.rewards_memory = []\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "        self.model_name=model_name        \n",
        "        self.iteration=iteration\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence<self.turbulence_threshold:\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += \\\n",
        "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\n",
        "                \n",
        "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just clear out all positions \n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\n",
        "                self.state[index+STOCK_DIM+1] =0\n",
        "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence< self.turbulence_threshold:\n",
        "            available_amount = self.state[0] // self.state[index+1]\n",
        "            # print('available_amount:{}'.format(available_amount))\n",
        "            \n",
        "            #update balance\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
        "            \n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just stop buying\n",
        "            pass\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('results/account_value_trade_{}_{}.png'.format(self.model_name, self.iteration))\n",
        "            plt.close()\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('results/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "\n",
        "            print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))- self.asset_memory[0] ))\n",
        "            print(\"total_cost: \", self.cost)\n",
        "            print(\"total trades: \", self.trades)\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            print(\"Sharpe: \",sharpe)\n",
        "            \n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.to_csv('results/account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * HMAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            if self.turbulence>=self.turbulence_threshold:\n",
        "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n",
        "                \n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            self.turbulence = self.data['turbulence'].values[0]\n",
        "            #print(self.turbulence)\n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):  \n",
        "        if self.initial:\n",
        "            self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "            self.day = 0\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.turbulence = 0\n",
        "            self.cost = 0\n",
        "            self.trades = 0\n",
        "            self.terminal = False \n",
        "            #self.iteration=self.iteration\n",
        "            self.rewards_memory = []\n",
        "            #initiate state\n",
        "            self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                          self.data.adjcp.values.tolist() + \\\n",
        "                          [0]*STOCK_DIM + \\\n",
        "                          self.data.macd.values.tolist() + \\\n",
        "                          self.data.rsi.values.tolist()  + \\\n",
        "                          self.data.cci.values.tolist()  + \\\n",
        "                          self.data.adx.values.tolist() \n",
        "        else:\n",
        "            previous_total_asset = self.previous_state[0]+ \\\n",
        "            sum(np.array(self.previous_state[1:(STOCK_DIM+1)])*np.array(self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.asset_memory = [previous_total_asset]\n",
        "            #self.asset_memory = [self.previous_state[0]]\n",
        "            self.day = 0\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.turbulence = 0\n",
        "            self.cost = 0\n",
        "            self.trades = 0\n",
        "            self.terminal = False \n",
        "            #self.iteration=iteration\n",
        "            self.rewards_memory = []\n",
        "            #initiate state\n",
        "            #self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]\n",
        "            #[0]*STOCK_DIM + \\\n",
        "\n",
        "            self.state = [ self.previous_state[0]] + \\\n",
        "                          self.data.adjcp.values.tolist() + \\\n",
        "                          self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]+ \\\n",
        "                          self.data.macd.values.tolist() + \\\n",
        "                          self.data.rsi.values.tolist()  + \\\n",
        "                          self.data.cci.values.tolist()  + \\\n",
        "                          self.data.adx.values.tolist() \n",
        "            \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human',close=False):\n",
        "        return self.state\n",
        "    \n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJxWlDAzjeIa"
      },
      "source": [
        "# Defining Models\n",
        "\n",
        "**1) A2c :**\n",
        "\n",
        "A2C utilizes an advantage function to reduce the    variance of the policy gradient.\n",
        "\n",
        " A2C uses copies of the same agent working in parallel to update gradients with different data samples. \n",
        " \n",
        "Each agent works independently to interact with the same environment. After all of the parallel agents finish calculating their gradients, A2C uses a coordinator to pass the average gradients over all the agents to a global network.\n",
        "\n",
        "https://stable-baselines.readthedocs.io/en/master/modules/a2c.html\n",
        "\n",
        "**2) SAC** :\n",
        "\n",
        "Instead of only seeking to maximize the lifetime rewards, SAC seeks to also maximize the entropy of the policy. \n",
        "\n",
        "We want a high entropy in our policy to explicitly encourage exploration, to encourage the policy to assign equal probabilities to actions that have same or nearly equal Q-values, and also to ensure that it does not collapse into repeatedly selecting a particular action that could exploit some inconsistency in the approximated Q function. \n",
        "\n",
        "Therefore, SAC overcomes the brittleness problem by encouraging the policy network to explore and not assign a very high probability to any one part of the range of actions.\n",
        "\n",
        "https://stable-baselines.readthedocs.io/en/master/modules/sac.html\n",
        "\n",
        "\n",
        "**3) TD3**\n",
        "\n",
        "\n",
        "TD3 is inspired by double DQN and solves the issue of the overestimation of critic values and has the following changes over DDPG.\n",
        "\n",
        "https://stable-baselines.readthedocs.io/en/master/modules/td3.html\n",
        " \n",
        "\n",
        "1.   Using Two main critic networks apart from their target networks.\n",
        "2.   Delaying update for actor-network.\n",
        "3.   Action noise regularisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI9hfsLigbYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507d035b-b892-4c9e-dd3b-6b50a5b6a2b2"
      },
      "source": [
        "# common library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import gym\n",
        "\n",
        "# RL models from stable-baselines\n",
        "from stable_baselines import GAIL, SAC\n",
        "from stable_baselines import ACER\n",
        "from stable_baselines import PPO2\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines import DDPG\n",
        "from stable_baselines import TD3\n",
        "\n",
        "from stable_baselines.ddpg.policies import DDPGPolicy\n",
        "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\n",
        "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "# from preprocessing.preprocessors import *\n",
        "# from config import config\n",
        "\n",
        "# customized env\n",
        "# from env.EnvMultipleStock_train import StockEnvTrain\n",
        "# from env.EnvMultipleStock_validation import StockEnvValidation\n",
        "# from env.EnvMultipleStock_trade import StockEnvTrade\n",
        "\n",
        "def train_A2C(env_train, model_name, timesteps=25000):\n",
        "    \"\"\"A2C model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = A2C('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "def train_SAC(env_train, model_name, timesteps=25000):\n",
        "    \"\"\"SAC model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = SAC('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (SAC): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "def train_TD3(env_train, model_name, timesteps=25000):\n",
        "    \"\"\"TD3 model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = TD3('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (TD3): ', (end - start) / 60, ' minutes')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulj1nFwtkfoM"
      },
      "source": [
        "# run_ensemble_strategy\n",
        "\n",
        "Run Models one by one for each day for a quarter.\n",
        "\n",
        "1.   save the sharpe ratio of each model separtely\n",
        "2.   Later using the sharpe ratio as a decider , decide which model is performing better, use it to trade the next quarter\n",
        "3.   Also during that keep improving model weights by continually training all the models simultaneously \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf6nxZtqkrkM"
      },
      "source": [
        "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\n",
        "    \"\"\"Ensemble Strategy that combines PPO, A2C and DDPG\"\"\"\n",
        "    print(\"============Start Ensemble Strategy============\")\n",
        "    # for ensemble model, it's necessary to feed the last state\n",
        "    # of the previous model to the current model as the initial state\n",
        "    last_state_ensemble = []\n",
        "    \n",
        "    a2c_sharpe_list = []\n",
        "\n",
        "    td3_sharpe_list = []\n",
        "\n",
        "    sac_sharpe_list = []\n",
        "\n",
        "    model_use = []\n",
        "\n",
        "    # based on the analysis of the in-sample data\n",
        "    #turbulence_threshold = 140\n",
        "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
        "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
        "\n",
        "    #select threshold of upto .90 quantile\n",
        "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
        "    print(rebalance_window + validation_window, len(unique_trade_date), rebalance_window)\n",
        "    start = time.time()\n",
        "    \n",
        "    #rebalnce=valudation=63, unique trae dates are all unique dates we wiil be processing\n",
        "\n",
        "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
        "        print('iterations number:-',i,rebalance_window)\n",
        "        print(\"============================================\")\n",
        "        ## initial state is empty\n",
        "        if i - rebalance_window - validation_window == 0:\n",
        "            # inital state\n",
        "            initial = True\n",
        "        else:\n",
        "            # previous state\n",
        "            initial = False\n",
        "\n",
        "        # Tuning trubulence index based on historical data\n",
        "        # Turbulence lookback window is one quarter\n",
        "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
        "        start_date_index = end_date_index - validation_window*30 + 1\n",
        "\n",
        "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
        "        #historical_turbulence = df[(df.datadate<unique_trade_date[i - rebalance_window - validation_window]) & (df.datadate>=(unique_trade_date[i - rebalance_window - validation_window - 63]))]\n",
        "\n",
        "\n",
        "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
        "\n",
        "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
        "\n",
        "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
        "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
        "            # then we assume that the current market is volatile,\n",
        "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
        "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
        "            turbulence_threshold = insample_turbulence_threshold\n",
        "        else:\n",
        "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
        "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
        "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
        "        print(\"turbulence_threshold: \", turbulence_threshold)\n",
        "\n",
        "        ############## Environment Setup starts ##############\n",
        "        ## training env\n",
        "\n",
        "        ##Creates a simple vectorized wrapper for multiple environments, calling each environment in sequence on the current Python process\n",
        "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
        "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
        "\n",
        "        ## validation env\n",
        "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
        "                                end=unique_trade_date[i - rebalance_window])\n",
        "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
        "                                                          turbulence_threshold=turbulence_threshold,\n",
        "                                                          iteration=i)])\n",
        "        obs_val = env_val.reset()\n",
        "        ############## Environment Setup ends ##############\n",
        "\n",
        "        ############## Training and Validation starts ##############\n",
        "        print(\"======Model training from: \", 20090000, \"to \",\n",
        "              unique_trade_date[i - rebalance_window - validation_window])\n",
        "        # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
        "        # print(\"==============Model Training===========\")\n",
        "        print(\"======A2C Training========\")\n",
        "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i))\n",
        "        print(\"======A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_a2c = get_validation_sharpe(i)\n",
        "        print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
        "\n",
        "\n",
        "\n",
        "        print(\"======TD3 Training========\")\n",
        "        model_td3 = train_TD3(env_train, model_name=\"TD3_30k_dow_{}\".format(i))\n",
        "        print(\"======TD3 Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_td3, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_td3 = get_validation_sharpe(i)\n",
        "        print(\"TD3 Sharpe Ratio: \", sharpe_td3)\n",
        "\n",
        "\n",
        "        print(\"======SAC Training========\")\n",
        "        model_sac = train_SAC(env_train, model_name=\"SAC_30k_dow_{}\".format(i))\n",
        "        print(\"======SAC Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_sac, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_sac = get_validation_sharpe(i)\n",
        "        print(\"SAC Sharpe Ratio: \", sharpe_sac)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        a2c_sharpe_list.append(sharpe_a2c)\n",
        "        td3_sharpe_list.append(sharpe_td3)\n",
        "        sac_sharpe_list.append(sharpe_sac)\n",
        "        \n",
        "        # Model Selection based on sharpe ratio\n",
        "        all_sharpes= [ sharpe_a2c  ,sharpe_td3 ,sharpe_sac ]\n",
        "        names_sharpes =[\n",
        "                        (model_a2c,'A2C'),             \n",
        "                        (model_td3,'TD3'),\n",
        "                        (model_sac,'SAC')         \n",
        "                        ]\n",
        "        MAX_SHARPE=all_sharpes.index(max(all_sharpes))\n",
        "        model_ensemble=names_sharpes[MAX_SHARPE][0]\n",
        "        model_use.append(names_sharpes[MAX_SHARPE][1])\n",
        "\n",
        "        print('*'*100)\n",
        "        print('picked up technique',names_sharpes[MAX_SHARPE][0])\n",
        "\n",
        "        ############## Training and Validation ends ##############\n",
        "\n",
        "        ############## Trading starts ##############\n",
        "        print(\"======Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
        "        #print(\"Used Model: \", model_ensemble)\n",
        "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
        "                                             last_state=last_state_ensemble, iter_num=i,\n",
        "                                             unique_trade_date=unique_trade_date,\n",
        "                                             rebalance_window=rebalance_window,\n",
        "                                             turbulence_threshold=turbulence_threshold,\n",
        "                                             initial=initial)\n",
        "        # print(\"============Trading Done============\")\n",
        "        ############## Trading ends ##############\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWFjOMtYjvNe"
      },
      "source": [
        "def DRL_prediction(df,\n",
        "                   model,\n",
        "                   name,\n",
        "                   last_state,\n",
        "                   iter_num,\n",
        "                   unique_trade_date,\n",
        "                   rebalance_window,\n",
        "                   turbulence_threshold,\n",
        "                   initial):\n",
        "    ### make a prediction based on trained model###\n",
        "\n",
        "    ## trading env\n",
        "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n",
        "    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\n",
        "                                                   turbulence_threshold=turbulence_threshold,\n",
        "                                                   initial=initial,\n",
        "                                                   previous_state=last_state,\n",
        "                                                   model_name=name,\n",
        "                                                   iteration=iter_num)])\n",
        "    obs_trade = env_trade.reset()\n",
        "\n",
        "    for i in range(len(trade_data.index.unique())):\n",
        "        action, _states = model.predict(obs_trade)\n",
        "        obs_trade, rewards, dones, info = env_trade.step(action)\n",
        "        if i == (len(trade_data.index.unique()) - 2):\n",
        "            # print(env_test.render())\n",
        "            last_state = env_trade.render()\n",
        "\n",
        "    df_last_state = pd.DataFrame({'last_state': last_state})\n",
        "    df_last_state.to_csv('results/last_state_{}_{}.csv'.format(name, i), index=False)\n",
        "    return last_state\n",
        "\n",
        "\n",
        "def DRL_validation(model, test_data, test_env, test_obs) -> None:\n",
        "    ###validation process###\n",
        "    for i in range(len(test_data.index.unique())):\n",
        "        action, _states = model.predict(test_obs)\n",
        "        test_obs, rewards, dones, info = test_env.step(action)\n",
        "\n",
        "\n",
        "def get_validation_sharpe(iteration):\n",
        "    ###Calculate Sharpe ratio based on validation results###\n",
        "    df_total_value = pd.read_csv('results/account_value_validation_{}.csv'.format(iteration), index_col=0)\n",
        "    df_total_value.columns = ['account_value_train']\n",
        "    df_total_value['daily_return'] = df_total_value.pct_change(1)\n",
        "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n",
        "             df_total_value['daily_return'].std()\n",
        "    return sharpe\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uflvWbVygfeN"
      },
      "source": [
        "# common library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "\n",
        "# preprocessor\n",
        "# from preprocessing.preprocessors import *\n",
        "# config\n",
        "# from config.config import *\n",
        "# model\n",
        "# from model.models import *\n",
        "import os\n",
        "\n",
        "def run_model() -> None:\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "\n",
        "    # read and preprocess data\n",
        "    preprocessed_path = \"done_data.csv\"\n",
        "    if os.path.exists(preprocessed_path):\n",
        "        data = pd.read_csv(preprocessed_path, index_col=0)\n",
        "    else:\n",
        "        data = preprocess_data()\n",
        "        data = add_turbulence(data)\n",
        "        data.to_csv(preprocessed_path)\n",
        "\n",
        "    print(data.head())\n",
        "    print(data.size)\n",
        "\n",
        "    # 2015/10/01 is the date that validation starts\n",
        "    # 2016/01/01 is the date that real trading starts\n",
        "    # unique_trade_date needs to start from 2015/10/01 for validation purpose\n",
        "    unique_trade_date = data[(data.datadate > 20151001)&(data.datadate <= 20200707)].datadate.unique()\n",
        "    print(unique_trade_date)\n",
        "\n",
        "    # rebalance_window is the number of months to retrain the model\n",
        "    # validation_window is the number of months to validation the model and select for trading\n",
        "    rebalance_window = 63\n",
        "    validation_window = 63\n",
        "    \n",
        "    ## Ensemble Strategy\n",
        "    run_ensemble_strategy(df=data, \n",
        "                          unique_trade_date= unique_trade_date,\n",
        "                          rebalance_window = rebalance_window,\n",
        "                          validation_window=validation_window)\n",
        "\n",
        "    #_logger.info(f\"saving model version: {_version}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDh9JIK9pDva"
      },
      "source": [
        "import os\n",
        "try:\n",
        "  os.mkdir('results')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xib2wKlk4GY",
        "outputId": "4552fed5-0348-4928-9738-1eb2258cb7d8"
      },
      "source": [
        "run_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   datadate   tic      adjcp       open  ...    rsi        cci    adx  turbulence\n",
            "0  20090102  AAPL  12.964286  12.268571  ...  100.0  66.666667  100.0         0.0\n",
            "1  20090102   AXP  19.330000  18.570000  ...  100.0  66.666667  100.0         0.0\n",
            "2  20090102    BA  45.250000  42.800000  ...  100.0  66.666667  100.0         0.0\n",
            "3  20090102   CAT  46.910000  44.910000  ...    0.0  66.666667  100.0         0.0\n",
            "4  20090102  CSCO  16.960000  16.410000  ...  100.0  66.666667  100.0         0.0\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "1053360\n",
            "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n",
            "============Start Ensemble Strategy============\n",
            "126 1198 63\n",
            "iterations number:- 126 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20151002\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3146259784698486  minutes\n",
            "======A2C Validation from:  20151002 to  20160104\n",
            "A2C Sharpe Ratio:  0.05257116716227322\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.4528332352638245  minutes\n",
            "======TD3 Validation from:  20151002 to  20160104\n",
            "TD3 Sharpe Ratio:  -0.1024286312882991\n",
            "======SAC Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/sac/policies.py:63: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Training time (SAC):  2.628984280427297  minutes\n",
            "======SAC Validation from:  20151002 to  20160104\n",
            "SAC Sharpe Ratio:  0.03325471803054627\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5faf7ac8>\n",
            "======Trading from:  20160104 to  20160405\n",
            "previous_total_asset:1000000\n",
            "end_total_asset:1075968.8744579365\n",
            "total_reward:75968.8744579365\n",
            "total_cost:  3846.8295662703576\n",
            "total trades:  1382\n",
            "Sharpe:  0.24752061603150652\n",
            "iterations number:- 189 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20160104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2619969646135967  minutes\n",
            "======A2C Validation from:  20160104 to  20160405\n",
            "A2C Sharpe Ratio:  0.14062077434483983\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.452871859073639  minutes\n",
            "======TD3 Validation from:  20160104 to  20160405\n",
            "TD3 Sharpe Ratio:  0.12992493167365934\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.580061725775401  minutes\n",
            "======SAC Validation from:  20160104 to  20160405\n",
            "SAC Sharpe Ratio:  0.13257483982556584\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5d63ee80>\n",
            "======Trading from:  20160405 to  20160705\n",
            "previous_total_asset:1075968.8744579365\n",
            "end_total_asset:1098168.7140126457\n",
            "total_reward:22199.83955470915\n",
            "total_cost:  4106.888033940283\n",
            "total trades:  1414\n",
            "Sharpe:  0.09018512080771023\n",
            "iterations number:- 252 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20160405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2761027693748475  minutes\n",
            "======A2C Validation from:  20160405 to  20160705\n",
            "A2C Sharpe Ratio:  -0.052552241620852695\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.4425175070762633  minutes\n",
            "======TD3 Validation from:  20160405 to  20160705\n",
            "TD3 Sharpe Ratio:  0.04353360806216335\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.626325980822245  minutes\n",
            "======SAC Validation from:  20160405 to  20160705\n",
            "SAC Sharpe Ratio:  -0.02675592405939015\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.td3.td3.TD3 object at 0x7f1d551c54e0>\n",
            "======Trading from:  20160705 to  20161003\n",
            "previous_total_asset:1098168.7140126457\n",
            "end_total_asset:1086431.3259129913\n",
            "total_reward:-11737.388099654345\n",
            "total_cost:  1233.1439039792672\n",
            "total trades:  1079\n",
            "Sharpe:  -0.05096554677601174\n",
            "iterations number:- 315 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20160705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2833118081092834  minutes\n",
            "======A2C Validation from:  20160705 to  20161003\n",
            "A2C Sharpe Ratio:  0.05586930749771744\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.4726978739102683  minutes\n",
            "======TD3 Validation from:  20160705 to  20161003\n",
            "TD3 Sharpe Ratio:  0.06268135574904006\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.638744425773621  minutes\n",
            "======SAC Validation from:  20160705 to  20161003\n",
            "SAC Sharpe Ratio:  -0.05289983787706648\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.td3.td3.TD3 object at 0x7f1d55447be0>\n",
            "======Trading from:  20161003 to  20170103\n",
            "previous_total_asset:1086431.3259129913\n",
            "end_total_asset:1112215.3302705083\n",
            "total_reward:25784.004357517\n",
            "total_cost:  738.6145001307083\n",
            "total trades:  1261\n",
            "Sharpe:  0.13061887296158625\n",
            "iterations number:- 378 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20161003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2850955804189046  minutes\n",
            "======A2C Validation from:  20161003 to  20170103\n",
            "A2C Sharpe Ratio:  0.38190658506821024\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.492231265703837  minutes\n",
            "======TD3 Validation from:  20161003 to  20170103\n",
            "TD3 Sharpe Ratio:  0.2997140110859173\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.691588846842448  minutes\n",
            "======SAC Validation from:  20161003 to  20170103\n",
            "SAC Sharpe Ratio:  0.4262900923276855\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d55e60048>\n",
            "======Trading from:  20170103 to  20170404\n",
            "previous_total_asset:1112215.3302705083\n",
            "end_total_asset:1134239.4690633256\n",
            "total_reward:22024.138792817248\n",
            "total_cost:  316.9364918267333\n",
            "total trades:  1079\n",
            "Sharpe:  0.14035278977543042\n",
            "iterations number:- 441 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20170103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3075170079867044  minutes\n",
            "======A2C Validation from:  20170103 to  20170404\n",
            "A2C Sharpe Ratio:  0.22986181459419122\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5010783235232035  minutes\n",
            "======TD3 Validation from:  20170103 to  20170404\n",
            "TD3 Sharpe Ratio:  0.42992141596432115\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6679622888565064  minutes\n",
            "======SAC Validation from:  20170103 to  20170404\n",
            "SAC Sharpe Ratio:  0.4821339619218269\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d5a5b3668>\n",
            "======Trading from:  20170404 to  20170705\n",
            "previous_total_asset:1134239.4690633256\n",
            "end_total_asset:1146968.642598679\n",
            "total_reward:12729.173535353504\n",
            "total_cost:  4251.124248239292\n",
            "total trades:  856\n",
            "Sharpe:  0.09863469296043134\n",
            "iterations number:- 504 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20170404\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3059820493062337  minutes\n",
            "======A2C Validation from:  20170404 to  20170705\n",
            "A2C Sharpe Ratio:  0.10349227620835312\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.479513438542684  minutes\n",
            "======TD3 Validation from:  20170404 to  20170705\n",
            "TD3 Sharpe Ratio:  0.3207158126129014\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6520727912584943  minutes\n",
            "======SAC Validation from:  20170404 to  20170705\n",
            "SAC Sharpe Ratio:  0.41887910390434857\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d5a8dbcc0>\n",
            "======Trading from:  20170705 to  20171003\n",
            "previous_total_asset:1146968.642598679\n",
            "end_total_asset:1236031.1101415071\n",
            "total_reward:89062.46754282806\n",
            "total_cost:  3795.1088777843665\n",
            "total trades:  1012\n",
            "Sharpe:  0.47632333410709027\n",
            "iterations number:- 567 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20170705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3109439929326376  minutes\n",
            "======A2C Validation from:  20170705 to  20171003\n",
            "A2C Sharpe Ratio:  0.6560400911747685\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.4725680390993756  minutes\n",
            "======TD3 Validation from:  20170705 to  20171003\n",
            "TD3 Sharpe Ratio:  0.4155195277746702\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6244464039802553  minutes\n",
            "======SAC Validation from:  20170705 to  20171003\n",
            "SAC Sharpe Ratio:  0.07437203653072137\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5c28a080>\n",
            "======Trading from:  20171003 to  20180103\n",
            "previous_total_asset:1236031.1101415071\n",
            "end_total_asset:1374797.1052397192\n",
            "total_reward:138765.99509821204\n",
            "total_cost:  4197.3125471408885\n",
            "total trades:  1409\n",
            "Sharpe:  0.6614407489040801\n",
            "iterations number:- 630 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20171003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3175834576288858  minutes\n",
            "======A2C Validation from:  20171003 to  20180103\n",
            "A2C Sharpe Ratio:  0.385132185131379\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.47408177057902  minutes\n",
            "======TD3 Validation from:  20171003 to  20180103\n",
            "TD3 Sharpe Ratio:  0.6397847669843865\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6792434732119244  minutes\n",
            "======SAC Validation from:  20171003 to  20180103\n",
            "SAC Sharpe Ratio:  0.4696892934352304\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.td3.td3.TD3 object at 0x7f1d5a8856d8>\n",
            "======Trading from:  20180103 to  20180405\n",
            "previous_total_asset:1374797.1052397192\n",
            "end_total_asset:1399336.6127966125\n",
            "total_reward:24539.507556893397\n",
            "total_cost:  2550.9224020099623\n",
            "total trades:  262\n",
            "Sharpe:  0.09684220575955024\n",
            "iterations number:- 693 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20180103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3339353601137798  minutes\n",
            "======A2C Validation from:  20180103 to  20180405\n",
            "A2C Sharpe Ratio:  -0.007028250321931005\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.56221186319987  minutes\n",
            "======TD3 Validation from:  20180103 to  20180405\n",
            "TD3 Sharpe Ratio:  -0.07524721265207887\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.707955038547516  minutes\n",
            "======SAC Validation from:  20180103 to  20180405\n",
            "SAC Sharpe Ratio:  -0.04561855457952625\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5daf5a20>\n",
            "======Trading from:  20180405 to  20180705\n",
            "previous_total_asset:1399336.6127966125\n",
            "end_total_asset:1385305.8586153672\n",
            "total_reward:-14030.754181245342\n",
            "total_cost:  5449.936763782246\n",
            "total trades:  880\n",
            "Sharpe:  -0.07215444810610347\n",
            "iterations number:- 756 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20180405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3475492954254151  minutes\n",
            "======A2C Validation from:  20180405 to  20180705\n",
            "A2C Sharpe Ratio:  -0.04398087307235039\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5160929044087728  minutes\n",
            "======TD3 Validation from:  20180405 to  20180705\n",
            "TD3 Sharpe Ratio:  0.1792705684384849\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6626657207806903  minutes\n",
            "======SAC Validation from:  20180405 to  20180705\n",
            "SAC Sharpe Ratio:  -0.08356682432906136\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.td3.td3.TD3 object at 0x7f1d5c21f208>\n",
            "======Trading from:  20180705 to  20181003\n",
            "previous_total_asset:1385305.8586153672\n",
            "end_total_asset:1392852.2514453672\n",
            "total_reward:7546.392830000026\n",
            "total_cost:  5487.653949999995\n",
            "total trades:  583\n",
            "Sharpe:  0.08229985855311131\n",
            "iterations number:- 819 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20180705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3313049952189127  minutes\n",
            "======A2C Validation from:  20180705 to  20181003\n",
            "A2C Sharpe Ratio:  0.2651557537323326\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5008957862854  minutes\n",
            "======TD3 Validation from:  20180705 to  20181003\n",
            "TD3 Sharpe Ratio:  0.1989201398915728\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.697931408882141  minutes\n",
            "======SAC Validation from:  20180705 to  20181003\n",
            "SAC Sharpe Ratio:  0.1216847380550514\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5bf52e10>\n",
            "======Trading from:  20181003 to  20190104\n",
            "previous_total_asset:1392852.2514453672\n",
            "end_total_asset:1398589.291925621\n",
            "total_reward:5737.040480253752\n",
            "total_cost:  712.3791812876066\n",
            "total trades:  148\n",
            "Sharpe:  0.20496814138442948\n",
            "iterations number:- 882 63\n",
            "============================================\n",
            "turbulence_threshold:  171.09407156310274\n",
            "======Model training from:  20090000 to  20181003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.341351322333018  minutes\n",
            "======A2C Validation from:  20181003 to  20190104\n",
            "A2C Sharpe Ratio:  -0.37077615028887095\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.549868098894755  minutes\n",
            "======TD3 Validation from:  20181003 to  20190104\n",
            "TD3 Sharpe Ratio:  -0.3776236063666057\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6746850967407227  minutes\n",
            "======SAC Validation from:  20181003 to  20190104\n",
            "SAC Sharpe Ratio:  -0.35351717525085347\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d56039518>\n",
            "======Trading from:  20190104 to  20190405\n",
            "previous_total_asset:1398589.291925621\n",
            "end_total_asset:1484756.5325404846\n",
            "total_reward:86167.24061486358\n",
            "total_cost:  1718.0628468256832\n",
            "total trades:  876\n",
            "Sharpe:  0.2385321444794173\n",
            "iterations number:- 945 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20190104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.340313231945038  minutes\n",
            "======A2C Validation from:  20190104 to  20190405\n",
            "A2C Sharpe Ratio:  0.11445012970839723\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.56724701722463  minutes\n",
            "======TD3 Validation from:  20190104 to  20190405\n",
            "TD3 Sharpe Ratio:  0.04842838675512656\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.6840474088986714  minutes\n",
            "======SAC Validation from:  20190104 to  20190405\n",
            "SAC Sharpe Ratio:  0.023046898989669176\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5d859b38>\n",
            "======Trading from:  20190405 to  20190708\n",
            "previous_total_asset:1484756.5325404846\n",
            "end_total_asset:1486715.106318214\n",
            "total_reward:1958.5737777294125\n",
            "total_cost:  1120.799445314622\n",
            "total trades:  155\n",
            "Sharpe:  0.10390916204341057\n",
            "iterations number:- 1008 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20190405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.356667653719584  minutes\n",
            "======A2C Validation from:  20190405 to  20190708\n",
            "A2C Sharpe Ratio:  0.208928815728233\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5450175484021504  minutes\n",
            "======TD3 Validation from:  20190405 to  20190708\n",
            "TD3 Sharpe Ratio:  0.4299341299498422\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.685585784912109  minutes\n",
            "======SAC Validation from:  20190405 to  20190708\n",
            "SAC Sharpe Ratio:  0.2599588275099478\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.td3.td3.TD3 object at 0x7f1d5a47e550>\n",
            "======Trading from:  20190708 to  20191004\n",
            "previous_total_asset:1486715.106318214\n",
            "end_total_asset:1487577.6265437738\n",
            "total_reward:862.5202255598269\n",
            "total_cost:  3141.588576466189\n",
            "total trades:  304\n",
            "Sharpe:  0.014212969030934294\n",
            "iterations number:- 1071 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20190708\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3481627623240153  minutes\n",
            "======A2C Validation from:  20190708 to  20191004\n",
            "A2C Sharpe Ratio:  -0.15157639059187375\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.567660939693451  minutes\n",
            "======TD3 Validation from:  20190708 to  20191004\n",
            "TD3 Sharpe Ratio:  -0.05996380782072201\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.740641502539317  minutes\n",
            "======SAC Validation from:  20190708 to  20191004\n",
            "SAC Sharpe Ratio:  0.07393347983569855\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d5f72b940>\n",
            "======Trading from:  20191004 to  20200106\n",
            "previous_total_asset:1487577.6265437738\n",
            "end_total_asset:1486135.9009465845\n",
            "total_reward:-1441.7255971892737\n",
            "total_cost:  326.04007704322817\n",
            "total trades:  48\n",
            "Sharpe:  -0.45292998205326945\n",
            "iterations number:- 1134 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20191004\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3527633468310039  minutes\n",
            "======A2C Validation from:  20191004 to  20200106\n",
            "A2C Sharpe Ratio:  -0.3717695575784297\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5545530398686727  minutes\n",
            "======TD3 Validation from:  20191004 to  20200106\n",
            "TD3 Sharpe Ratio:  -0.09856122484557446\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.729140754540761  minutes\n",
            "======SAC Validation from:  20191004 to  20200106\n",
            "SAC Sharpe Ratio:  0.012147482755454493\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.sac.sac.SAC object at 0x7f1d5d8b3668>\n",
            "======Trading from:  20200106 to  20200406\n",
            "previous_total_asset:1486135.9009465845\n",
            "end_total_asset:1459163.0544465843\n",
            "total_reward:-26972.846500000218\n",
            "total_cost:  1565.1064999999994\n",
            "total trades:  170\n",
            "Sharpe:  -0.3860006628344249\n",
            "iterations number:- 1197 63\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358296\n",
            "======Model training from:  20090000 to  20200106\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.3765787402788798  minutes\n",
            "======A2C Validation from:  20200106 to  20200406\n",
            "A2C Sharpe Ratio:  -0.39885864300604656\n",
            "======TD3 Training========\n",
            "Training time (TD3):  2.5907735149065654  minutes\n",
            "======TD3 Validation from:  20200106 to  20200406\n",
            "TD3 Sharpe Ratio:  -0.40949706832301147\n",
            "======SAC Training========\n",
            "Training time (SAC):  2.762481383482615  minutes\n",
            "======SAC Validation from:  20200106 to  20200406\n",
            "SAC Sharpe Ratio:  -0.4157971740687871\n",
            "****************************************************************************************************\n",
            "picked up technique <stable_baselines.a2c.a2c.A2C object at 0x7f1d5fbe51d0>\n",
            "======Trading from:  20200406 to  20200707\n",
            "previous_total_asset:1459163.0544465843\n",
            "end_total_asset:1461371.5270139447\n",
            "total_reward:2208.4725673603825\n",
            "total_cost:  413.45851048863176\n",
            "total trades:  109\n",
            "Sharpe:  0.1670116035373024\n",
            "Ensemble Strategy took:  117.48891602357229  minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD0q_N5hRmXO"
      },
      "source": [
        "# Total Profit of $461371"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgBoEO6dR-uw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}